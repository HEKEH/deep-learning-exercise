"""
Softmaxå›å½’ - ä»é›¶å¼€å§‹å®ç°
è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„æœºå™¨å­¦ä¹ é¡¹ç›®ï¼Œæ•™ä½ å¦‚ä½•ä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªå›¾åƒåˆ†ç±»æ¨¡å‹

å­¦ä¹ ç›®æ ‡ï¼š
1. ç†è§£æœºå™¨å­¦ä¹ çš„å®Œæ•´æµç¨‹
2. å­¦ä¼šå¦‚ä½•åŠ è½½å’Œå¤„ç†æ•°æ®
3. ç†è§£æ¨¡å‹æ„å»ºå’Œè®­ç»ƒè¿‡ç¨‹
4. å­¦ä¼šå¦‚ä½•è¯„ä¼°å’Œæ”¹è¿›æ¨¡å‹

ä½œè€…ï¼šä¸ºåˆå­¦è€…ä¼˜åŒ–
"""

# ==================== ç¬¬ä¸€æ­¥ï¼šå¯¼å…¥å¿…è¦çš„åº“ ====================
# è¿™äº›åº“å°±åƒå·¥å…·ç®±ï¼Œæ¯ä¸ªéƒ½æœ‰ç‰¹å®šçš„ç”¨é€”
import torch  # PyTorchï¼šæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå°±åƒæˆ‘ä»¬çš„"å¤§è„‘"
import matplotlib  # ç»˜å›¾åº“ï¼Œç”¨æ¥å¯è§†åŒ–ç»“æœ
import matplotlib.pyplot as plt  # ç»˜å›¾å·¥å…·
import sys  # ç³»ç»Ÿç›¸å…³åŠŸèƒ½
import os  # æ–‡ä»¶å’Œç›®å½•æ“ä½œ
from torch import Tensor  # PyTorchçš„å¼ é‡ç±»å‹
from d2l import torch as d2l  # æ·±åº¦å­¦ä¹ å·¥å…·åº“
from typing import List, Tuple, Optional, Union, Any  # ç±»å‹æç¤º
import torchvision  # è®¡ç®—æœºè§†è§‰åº“
from torchvision import transforms  # å›¾åƒå˜æ¢å·¥å…·
from torch.utils.data import DataLoader  # æ•°æ®åŠ è½½å™¨

# ==================== ç¬¬äºŒæ­¥ï¼šé…ç½®æ˜¾ç¤ºç¯å¢ƒ ====================
# è¿™ä¸€æ­¥ç¡®ä¿å›¾å½¢èƒ½å¤Ÿæ­£ç¡®æ˜¾ç¤ºï¼Œå°±åƒè®¾ç½®æ˜¾ç¤ºå™¨ä¸€æ ·
def setup_matplotlib() -> bool:
    """
    é…ç½®matplotlibä»¥ç¡®ä¿å›¾å½¢èƒ½æ­£å¸¸æ˜¾ç¤º
    å°±åƒè®¾ç½®ç”µè§†æœºçš„æ˜¾ç¤ºæ¨¡å¼ä¸€æ ·
    """
    try:
        # æ£€æŸ¥æ˜¯å¦åœ¨Jupyterç¯å¢ƒä¸­ï¼ˆå°±åƒæ£€æŸ¥æ˜¯å¦åœ¨ç½‘é¡µä¸­è¿è¡Œï¼‰
        if 'ipykernel' in sys.modules:
            matplotlib.use('TkAgg')  # ä½¿ç”¨TkAggåç«¯
            # åœ¨Jupyterä¸­è®¾ç½®å†…è”æ˜¾ç¤ºï¼ˆå›¾å½¢ç›´æ¥æ˜¾ç¤ºåœ¨ç½‘é¡µä¸­ï¼‰
            try:
                from IPython import get_ipython
                get_ipython().run_line_magic('matplotlib', 'inline')
            except (NameError, ImportError):
                print("IPythonä¸å¯ç”¨ï¼Œè·³è¿‡å†…è”æ˜¾ç¤ºè®¾ç½®")
        else:
            # åœ¨æ™®é€šPythonç¯å¢ƒä¸­ä½¿ç”¨TkAggï¼ˆå¼¹å‡ºçª—å£æ˜¾ç¤ºï¼‰
            matplotlib.use('TkAgg')

        # è®¾ç½®å›¾å½¢å‚æ•°ï¼ˆå°±åƒè®¾ç½®ç”»å¸ƒçš„å¤§å°å’Œæ ·å¼ï¼‰
        plt.rcParams['figure.figsize'] = (10, 6)  # å›¾å½¢å¤§å°
        plt.rcParams['font.size'] = 12  # å­—ä½“å¤§å°
        plt.rcParams['axes.grid'] = True  # æ˜¾ç¤ºç½‘æ ¼
        plt.rcParams['grid.alpha'] = 0.3  # ç½‘æ ¼é€æ˜åº¦

        print("âœ… matplotlibé…ç½®å®Œæˆ - å›¾å½¢å¯ä»¥æ­£å¸¸æ˜¾ç¤ºäº†ï¼")
        return True
    except Exception as e:
        print(f"âŒ matplotlibé…ç½®å¤±è´¥: {e}")
        return False

# åˆå§‹åŒ–matplotlib
print("ğŸ”§ æ­£åœ¨é…ç½®æ˜¾ç¤ºç¯å¢ƒ...")
setup_matplotlib()

# ==================== ç¬¬ä¸‰æ­¥ï¼šå®šä¹‰è¾…åŠ©å·¥å…·ç±» ====================

class Accumulator:
    """
    ç´¯åŠ å™¨ç±» - ç”¨æ¥ç»Ÿè®¡è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§æŒ‡æ ‡
    å°±åƒè®°è´¦æœ¬ä¸€æ ·ï¼Œè®°å½•æ‰€æœ‰çš„æ•°æ®
    """
    def __init__(self, n: int) -> None:
        """
        åˆå§‹åŒ–ç´¯åŠ å™¨
        n: éœ€è¦ç»Ÿè®¡çš„æŒ‡æ ‡æ•°é‡ï¼ˆæ¯”å¦‚æŸå¤±ã€å‡†ç¡®ç‡ç­‰ï¼‰
        """
        self.data = [0.0] * n  # åˆ›å»ºnä¸ªè®¡æ•°å™¨ï¼Œåˆå§‹å€¼ä¸º0

    def add(self, *args: float) -> None:
        """
        æ·»åŠ æ–°çš„æ•°æ®
        *args: è¦æ·»åŠ çš„æ•°å€¼ï¼ˆæ¯”å¦‚å½“å‰æ‰¹æ¬¡çš„æŸå¤±ã€å‡†ç¡®ç‡ç­‰ï¼‰
        """
        self.data = [a + float(b) for a, b in zip(self.data, args)]

    def reset(self) -> None:
        """é‡ç½®æ‰€æœ‰è®¡æ•°å™¨ä¸º0"""
        self.data = [0.0] * len(self.data)

    def __getitem__(self, idx: int) -> float:
        """è·å–ç¬¬idxä¸ªæŒ‡æ ‡çš„å€¼"""
        return self.data[idx]

class Animator:
    """
    åŠ¨ç”»å™¨ç±» - å®æ—¶æ˜¾ç¤ºè®­ç»ƒè¿‡ç¨‹
    å°±åƒå®æ—¶ç›‘æ§å™¨ï¼Œæ˜¾ç¤ºè®­ç»ƒè¿›åº¦
    """
    def __init__(self, xlabel: Optional[str] = None, ylabel: Optional[str] = None,
                 legend: Optional[List[str]] = None, xlim: Optional[Tuple[float, float]] = None,
                 ylim: Optional[Tuple[float, float]] = None, xscale: str = 'linear',
                 yscale: str = 'linear', fmts: Tuple[str, ...] = ('-', 'm--', 'g-.', 'r:'),
                 nrows: int = 1, ncols: int = 1, figsize: Tuple[float, float] = (10, 6)) -> None:
        """
        åˆå§‹åŒ–åŠ¨ç”»å™¨
        xlabel: xè½´æ ‡ç­¾ï¼ˆæ¯”å¦‚"è®­ç»ƒè½®æ•°"ï¼‰
        ylabel: yè½´æ ‡ç­¾ï¼ˆæ¯”å¦‚"å‡†ç¡®ç‡"ï¼‰
        legend: å›¾ä¾‹ï¼ˆæ¯”å¦‚["è®­ç»ƒæŸå¤±", "è®­ç»ƒå‡†ç¡®ç‡", "æµ‹è¯•å‡†ç¡®ç‡"]ï¼‰
        """
        # å¢é‡åœ°ç»˜åˆ¶å¤šæ¡çº¿
        if legend is None:
            legend = []

        # å°è¯•ä½¿ç”¨SVGæ˜¾ç¤ºï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨æ™®é€šæ˜¾ç¤º
        try:
            d2l.use_svg_display()
        except:
            print("SVGæ˜¾ç¤ºä¸å¯ç”¨ï¼Œä½¿ç”¨æ™®é€šæ˜¾ç¤º")

        # åˆ›å»ºå›¾å½¢å’Œåæ ‡è½´
        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)
        if nrows * ncols == 1:
            self.axes = [self.axes, ]

        # ä½¿ç”¨lambdaå‡½æ•°æ•è·å‚æ•°ï¼Œç”¨äºé…ç½®åæ ‡è½´
        self.config_axes = lambda: d2l.set_axes(
            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)
        self.X, self.Y, self.fmts = None, None, fmts

        # æ£€æŸ¥displayæ¨¡å—æ˜¯å¦å¯ç”¨ï¼ˆç”¨äºJupyterç¯å¢ƒï¼‰
        try:
            from IPython import display
            self.display_available = True
            self.display = display
        except ImportError:
            self.display_available = False
            print("IPython displayä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨plt.show()")

    def add(self, x: Union[float, List[float]], y: Union[float, List[float]]) -> None:
        """
        æ·»åŠ æ–°çš„æ•°æ®ç‚¹å¹¶æ›´æ–°å›¾å½¢
        x: xè½´æ•°æ®ï¼ˆæ¯”å¦‚å½“å‰è½®æ•°ï¼‰
        y: yè½´æ•°æ®ï¼ˆæ¯”å¦‚å½“å‰çš„æŸå¤±å’Œå‡†ç¡®ç‡ï¼‰
        """
        # å¤„ç†æ•°æ®æ ¼å¼
        if not hasattr(y, "__len__"):
            y = [y]
        n = len(y)
        if not hasattr(x, "__len__"):
            x = [x] * n
        if not self.X:
            self.X = [[] for _ in range(n)]
        if not self.Y:
            self.Y = [[] for _ in range(n)]

        # æ·»åŠ æ–°æ•°æ®ç‚¹
        for i, (a, b) in enumerate(zip(x, y)):
            if a is not None and b is not None:
                self.X[i].append(a)
                self.Y[i].append(b)

        # æ¸…é™¤å½“å‰å›¾å½¢å¹¶é‡æ–°ç»˜åˆ¶
        self.axes[0].cla()
        for x_data, y_data, fmt in zip(self.X, self.Y, self.fmts):
            self.axes[0].plot(x_data, y_data, fmt, linewidth=2)

        self.config_axes()

        # æ ¹æ®ç¯å¢ƒé€‰æ‹©æ˜¾ç¤ºæ–¹å¼
        if self.display_available:
            try:
                self.display.display(self.fig)
                self.display.clear_output(wait=True)
            except:
                plt.show(block=False)
                plt.pause(0.1)
        else:
            plt.show(block=False)
            plt.pause(0.1)

        # ä¿å­˜å›¾å½¢åˆ°æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
        try:
            os.makedirs('./plots', exist_ok=True)
            plt.savefig('./plots/training_progress.png', dpi=300, bbox_inches='tight')
        except:
            pass

# ==================== ç¬¬å››æ­¥ï¼šåŠ è½½æ•°æ® ====================
# è¿™ä¸€æ­¥å°±åƒå‡†å¤‡å­¦ä¹ ææ–™ï¼Œæ•°æ®æ˜¯æœºå™¨å­¦ä¹ çš„"é£Ÿç‰©"

print("ğŸ“Š æ­£åœ¨åŠ è½½Fashion-MNISTæ•°æ®é›†...")
print("ğŸ’¡ æç¤ºï¼šFashion-MNISTæ˜¯ä¸€ä¸ªåŒ…å«10ç§è¡£æœç±»å‹çš„å›¾åƒæ•°æ®é›†")
print("   åŒ…æ‹¬ï¼šTæ¤ã€è£¤å­ã€è¿è¡£è£™ã€å¤–å¥—ã€å‡‰é‹ã€è¡¬è¡«ã€è¿åŠ¨é‹ã€åŒ…ã€é´å­ã€å‡‰é‹")

batch_size = 256  # æ‰¹æ¬¡å¤§å°ï¼šæ¯æ¬¡å¤„ç†256å¼ å›¾ç‰‡

def load_data_fashion_mnist(batch_size: int, resize: Optional[int] = None) -> Tuple[DataLoader, DataLoader]:
    """
    åŠ è½½Fashion-MNISTæ•°æ®é›†
    å°±åƒä»å›¾ä¹¦é¦†å€Ÿä¹¦ä¸€æ ·ï¼Œæˆ‘ä»¬éœ€è¦æŠŠæ•°æ®"å€Ÿ"åˆ°ç”µè„‘é‡Œ

    å‚æ•°ï¼š
    batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆæ¯æ¬¡å¤„ç†å¤šå°‘å¼ å›¾ç‰‡ï¼‰
    resize: æ˜¯å¦è°ƒæ•´å›¾ç‰‡å¤§å°

    è¿”å›ï¼š
    train_iter: è®­ç»ƒæ•°æ®åŠ è½½å™¨
    test_iter: æµ‹è¯•æ•°æ®åŠ è½½å™¨
    """
    # å®šä¹‰æ•°æ®å˜æ¢ï¼ˆå°±åƒç»™å›¾ç‰‡åšé¢„å¤„ç†ï¼‰
    trans = [transforms.ToTensor()]  # å°†å›¾ç‰‡è½¬æ¢ä¸ºå¼ é‡
    if resize:
        trans.insert(0, transforms.Resize(resize))  # è°ƒæ•´å›¾ç‰‡å¤§å°
    trans = transforms.Compose(trans)  # ç»„åˆæ‰€æœ‰å˜æ¢

    # ä¸‹è½½å¹¶åŠ è½½è®­ç»ƒæ•°æ®
    print("ğŸ“¥ ä¸‹è½½è®­ç»ƒæ•°æ®...")
    mnist_train = torchvision.datasets.FashionMNIST(
        root="./data", train=True, transform=trans, download=True)

    # ä¸‹è½½å¹¶åŠ è½½æµ‹è¯•æ•°æ®
    print("ğŸ“¥ ä¸‹è½½æµ‹è¯•æ•°æ®...")
    mnist_test = torchvision.datasets.FashionMNIST(
        root="./data", train=False, transform=trans, download=True)

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆå°±åƒæŠŠä¹¦æ•´ç†æˆå°å†Œå­ï¼‰
    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=4)
    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False, num_workers=4)

    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼")
    print(f"   è®­ç»ƒé›†ï¼š{len(mnist_train)} å¼ å›¾ç‰‡")
    print(f"   æµ‹è¯•é›†ï¼š{len(mnist_test)} å¼ å›¾ç‰‡")
    print(f"   æ‰¹æ¬¡å¤§å°ï¼š{batch_size}")

    return train_iter, test_iter

# åŠ è½½æ•°æ®
train_iter, test_iter = load_data_fashion_mnist(batch_size)

# ==================== ç¬¬äº”æ­¥ï¼šå®šä¹‰æ¨¡å‹ ====================
# è¿™ä¸€æ­¥å°±åƒè®¾è®¡ä¸€ä¸ª"å¤§è„‘"ï¼Œå‘Šè¯‰ç”µè„‘å¦‚ä½•æ€è€ƒ

print("\nğŸ§  æ­£åœ¨æ„å»ºæ¨¡å‹...")

# å®šä¹‰æ¨¡å‹å‚æ•°
number_inputs = 28 * 28  # è¾“å…¥ç»´åº¦ï¼šæ¯å¼ å›¾ç‰‡æ˜¯28x28åƒç´ ï¼Œå±•å¹³åæ˜¯784
number_outputs = 10      # è¾“å‡ºç»´åº¦ï¼š10ç§è¡£æœç±»å‹

print(f"ğŸ“ æ¨¡å‹å‚æ•°ï¼š")
print(f"   è¾“å…¥ç»´åº¦ï¼š{number_inputs} (28Ã—28åƒç´ )")
print(f"   è¾“å‡ºç»´åº¦ï¼š{number_outputs} (10ç§è¡£æœç±»å‹)")

# åˆå§‹åŒ–æƒé‡å’Œåç½®ï¼ˆå°±åƒç»™å¤§è„‘è®¾ç½®åˆå§‹çš„"æ€è€ƒæ–¹å¼"ï¼‰
W = torch.normal(0, 0.01, size=(number_inputs, number_outputs), requires_grad=True)  # æƒé‡çŸ©é˜µ
b = torch.zeros(number_outputs, requires_grad=True)  # åç½®å‘é‡

print(f"   æƒé‡çŸ©é˜µå½¢çŠ¶ï¼š{W.shape}")
print(f"   åç½®å‘é‡å½¢çŠ¶ï¼š{b.shape}")

# å®šä¹‰Softmaxå‡½æ•°ï¼ˆå°±åƒæŠ•ç¥¨é€‰ä¸¾ï¼ŒæŠŠåˆ†æ•°è½¬æ¢æˆæ¦‚ç‡ï¼‰
def softmax(X: Tensor) -> Tensor:
    """
    Softmaxå‡½æ•°ï¼šå°†ä»»æ„å®æ•°è½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒ
    å°±åƒæŠŠç¥¨æ•°è½¬æ¢æˆå½“é€‰æ¦‚ç‡ä¸€æ ·

    å‚æ•°ï¼š
    X: è¾“å…¥å¼ é‡ï¼ˆåŸå§‹åˆ†æ•°ï¼‰

    è¿”å›ï¼š
    æ¦‚ç‡åˆ†å¸ƒï¼ˆæ‰€æœ‰å€¼éƒ½æ˜¯æ­£æ•°ï¼Œä¸”å’Œä¸º1ï¼‰
    """
    X_exp = torch.exp(X)  # è®¡ç®—æŒ‡æ•°
    partition = X_exp.sum(1, keepdim=True)  # è®¡ç®—åˆ†æ¯ï¼ˆå½’ä¸€åŒ–å› å­ï¼‰
    return X_exp / partition  # è¿”å›æ¦‚ç‡åˆ†å¸ƒ

# å®šä¹‰ç½‘ç»œæ¨¡å‹ï¼ˆå°±åƒå®šä¹‰å¤§è„‘çš„æ€è€ƒè¿‡ç¨‹ï¼‰
def net(X: Tensor) -> Tensor:
    """
    ç½‘ç»œæ¨¡å‹ï¼šå®Œæ•´çš„é¢„æµ‹è¿‡ç¨‹
    å°±åƒå¤§è„‘çš„æ€è€ƒè¿‡ç¨‹ï¼šæ¥æ”¶è¾“å…¥ â†’ å¤„ç† â†’ è¾“å‡ºç»“æœ

    å‚æ•°ï¼š
    X: è¾“å…¥å›¾ç‰‡ï¼ˆå½¢çŠ¶ï¼š[æ‰¹æ¬¡å¤§å°, 784]ï¼‰

    è¿”å›ï¼š
    é¢„æµ‹ç»“æœï¼ˆå½¢çŠ¶ï¼š[æ‰¹æ¬¡å¤§å°, 10]ï¼‰
    """
    # 1. çº¿æ€§å˜æ¢ï¼šX * W + b
    linear_output = torch.matmul(X.reshape(-1, W.shape[0]), W) + b
    # 2. Softmaxæ¿€æ´»ï¼šå°†åˆ†æ•°è½¬æ¢ä¸ºæ¦‚ç‡
    return softmax(linear_output)

print("âœ… æ¨¡å‹æ„å»ºå®Œæˆï¼")

# ==================== ç¬¬å…­æ­¥ï¼šå®šä¹‰æŸå¤±å‡½æ•°å’Œè¯„ä¼°æŒ‡æ ‡ ====================

# å®šä¹‰äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼ˆå°±åƒè®¡ç®—é¢„æµ‹é”™è¯¯çš„ç¨‹åº¦ï¼‰
def cross_entropy(y_hat: Tensor, y: Tensor) -> Tensor:
    """
    äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼šè¡¡é‡é¢„æµ‹ä¸çœŸå®å€¼çš„å·®è·
    å°±åƒè€ƒè¯•è¯„åˆ†ï¼Œé”™è¯¯è¶Šå¤šåˆ†æ•°è¶Šä½

    å‚æ•°ï¼š
    y_hat: é¢„æµ‹ç»“æœï¼ˆæ¦‚ç‡åˆ†å¸ƒï¼‰
    y: çœŸå®æ ‡ç­¾

    è¿”å›ï¼š
    æŸå¤±å€¼ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
    """
    return -torch.log(y_hat[range(len(y_hat)), y])

# å®šä¹‰å‡†ç¡®ç‡è®¡ç®—å‡½æ•°ï¼ˆå°±åƒè®¡ç®—è€ƒè¯•çš„æ­£ç¡®ç‡ï¼‰
def accuracy(y_hat: Tensor, y: Tensor) -> float:
    """
    è®¡ç®—å‡†ç¡®ç‡ï¼šé¢„æµ‹æ­£ç¡®çš„æ¯”ä¾‹
    å°±åƒè®¡ç®—è€ƒè¯•çš„æ­£ç¡®ç‡

    å‚æ•°ï¼š
    y_hat: é¢„æµ‹ç»“æœ
    y: çœŸå®æ ‡ç­¾

    è¿”å›ï¼š
    å‡†ç¡®ç‡ï¼ˆ0-1ä¹‹é—´ï¼Œè¶Šå¤§è¶Šå¥½ï¼‰
    """
    if len(y_hat.shape) > 1:
        y_hat = y_hat.argmax(dim=1)  # å–æ¦‚ç‡æœ€å¤§çš„ç±»åˆ«ä½œä¸ºé¢„æµ‹ç»“æœ
    cmp = y_hat.type(y.dtype) == y  # æ¯”è¾ƒé¢„æµ‹å’ŒçœŸå®å€¼
    return float(cmp.type(y.dtype).sum())  # è¿”å›æ­£ç¡®é¢„æµ‹çš„æ•°é‡

# ==================== ç¬¬ä¸ƒæ­¥ï¼šå®šä¹‰è®­ç»ƒå’Œè¯„ä¼°å‡½æ•° ====================

def evaluate_accuracy(net: Union[torch.nn.Module, Any], data_iter: DataLoader) -> float:
    """
    è¯„ä¼°æ¨¡å‹åœ¨æŒ‡å®šæ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡
    å°±åƒç»™å­¦ç”Ÿåšæµ‹è¯•ï¼Œçœ‹çœ‹å­¦å¾—æ€ä¹ˆæ ·

    å‚æ•°ï¼š
    net: ç½‘ç»œæ¨¡å‹
    data_iter: æ•°æ®è¿­ä»£å™¨

    è¿”å›ï¼š
    å‡†ç¡®ç‡
    """
    if isinstance(net, torch.nn.Module):
        net.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

    metric = Accumulator(2)  # åˆ›å»ºç´¯åŠ å™¨ï¼Œè®°å½•æ­£ç¡®æ•°é‡å’Œæ€»æ•°é‡

    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦ï¼ˆèŠ‚çœå†…å­˜ï¼‰
        for X, y in data_iter:
            metric.add(accuracy(net(X), y), y.numel())  # ç´¯åŠ æ­£ç¡®æ•°é‡å’Œæ€»æ•°é‡

    return metric[0] / metric[1]  # è¿”å›å‡†ç¡®ç‡

def train_epoch_ch3(net: Union[torch.nn.Module, Any], train_iter: DataLoader,
                   loss: Any, updater: Union[torch.optim.Optimizer, Any]) -> Tuple[float, float]:
    """
    è®­ç»ƒä¸€ä¸ªå®Œæ•´çš„epochï¼ˆéå†æ‰€æœ‰è®­ç»ƒæ•°æ®ä¸€æ¬¡ï¼‰
    å°±åƒå­¦ç”Ÿåšä¸€æ¬¡å®Œæ•´çš„ç»ƒä¹ 

    å‚æ•°ï¼š
    net: ç½‘ç»œæ¨¡å‹
    train_iter: è®­ç»ƒæ•°æ®è¿­ä»£å™¨
    loss: æŸå¤±å‡½æ•°
    updater: ä¼˜åŒ–å™¨

    è¿”å›ï¼š
    (å¹³å‡æŸå¤±, å¹³å‡å‡†ç¡®ç‡)
    """
    if isinstance(net, torch.nn.Module):
        net.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼

    metric = Accumulator(3)  # è®°å½•æŸå¤±ã€æ­£ç¡®æ•°é‡ã€æ€»æ•°é‡

    for X, y in train_iter:  # éå†æ¯ä¸ªæ‰¹æ¬¡
        y_hat = net(X)  # å‰å‘ä¼ æ’­ï¼šè®¡ç®—é¢„æµ‹ç»“æœ
        l = loss(y_hat, y)  # è®¡ç®—æŸå¤±

        if isinstance(updater, torch.optim.Optimizer):
            # ä½¿ç”¨PyTorchä¼˜åŒ–å™¨
            updater.zero_grad()  # æ¸…ç©ºæ¢¯åº¦
            l.mean().backward()  # åå‘ä¼ æ’­ï¼šè®¡ç®—æ¢¯åº¦
            updater.step()  # æ›´æ–°å‚æ•°
        else:
            # ä½¿ç”¨è‡ªå®šä¹‰ä¼˜åŒ–å™¨
            l.mean().backward()  # åå‘ä¼ æ’­
            updater()  # æ›´æ–°å‚æ•°

        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())

    return metric[0] / metric[2], metric[1] / metric[2]  # è¿”å›å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡

# ==================== ç¬¬å…«æ­¥ï¼šå®šä¹‰ä¼˜åŒ–å™¨ ====================

def sgd(params: List[Tensor], lr: float) -> None:
    """
    éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨
    å°±åƒå­¦ç”Ÿæ ¹æ®é”™è¯¯è°ƒæ•´å­¦ä¹ æ–¹æ³•

    å‚æ•°ï¼š
    params: éœ€è¦æ›´æ–°çš„å‚æ•°åˆ—è¡¨
    lr: å­¦ä¹ ç‡ï¼ˆå­¦ä¹ æ­¥é•¿ï¼‰
    """
    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦
        for param in params:
            grad = param.grad  # è·å–æ¢¯åº¦
            assert grad is not None
            param -= lr * grad  # æ›´æ–°å‚æ•°ï¼šæ–°å‚æ•° = æ—§å‚æ•° - å­¦ä¹ ç‡ Ã— æ¢¯åº¦
            grad.zero_()  # æ¸…ç©ºæ¢¯åº¦

# è®¾ç½®å­¦ä¹ ç‡
lr = 0.1  # å­¦ä¹ ç‡ï¼šæ§åˆ¶æ¯æ¬¡æ›´æ–°çš„æ­¥é•¿

def updater() -> None:
    """æ›´æ–°å‡½æ•°ï¼šè°ƒç”¨SGDä¼˜åŒ–å™¨æ›´æ–°æ¨¡å‹å‚æ•°"""
    sgd([W, b], lr)

print(f"ğŸ”§ ä¼˜åŒ–å™¨è®¾ç½®å®Œæˆï¼å­¦ä¹ ç‡ï¼š{lr}")

# ==================== ç¬¬ä¹æ­¥ï¼šä¸»è®­ç»ƒå‡½æ•° ====================

def train_ch3(net: Union[torch.nn.Module, Any], train_iter: DataLoader,
              test_iter: DataLoader, loss: Any, num_epochs: int,
              updater: Union[torch.optim.Optimizer, Any]) -> None:
    """
    ä¸»è®­ç»ƒå‡½æ•°ï¼šå®Œæ•´çš„è®­ç»ƒè¿‡ç¨‹
    å°±åƒå­¦ç”Ÿçš„å®Œæ•´å­¦ä¹ è¿‡ç¨‹

    å‚æ•°ï¼š
    net: ç½‘ç»œæ¨¡å‹
    train_iter: è®­ç»ƒæ•°æ®
    test_iter: æµ‹è¯•æ•°æ®
    loss: æŸå¤±å‡½æ•°
    num_epochs: è®­ç»ƒè½®æ•°
    updater: ä¼˜åŒ–å™¨
    """
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒï¼æ€»å…± {num_epochs} è½®")
    print("ğŸ“ˆ è®­ç»ƒè¿‡ç¨‹å°†å®æ—¶æ˜¾ç¤ºæŸå¤±å’Œå‡†ç¡®ç‡å˜åŒ–...")

    # åˆ›å»ºåŠ¨ç”»å™¨ï¼Œç”¨äºå®æ—¶æ˜¾ç¤ºè®­ç»ƒè¿›åº¦
    animator = Animator(
        xlabel="è®­ç»ƒè½®æ•°",
        ylabel="æŒ‡æ ‡å€¼",
        xlim=[1, num_epochs],
        ylim=[0.0, 1.0],
        legend=['è®­ç»ƒæŸå¤±', 'è®­ç»ƒå‡†ç¡®ç‡', 'æµ‹è¯•å‡†ç¡®ç‡']
    )

    for epoch in range(num_epochs):
        print(f"\nğŸ”„ ç¬¬ {epoch + 1} è½®è®­ç»ƒ...")

        # è®­ç»ƒä¸€ä¸ªepoch
        train_loss, train_acc = train_epoch_ch3(net, train_iter, loss, updater)

        # è¯„ä¼°æµ‹è¯•é›†
        test_acc = evaluate_accuracy(net, test_iter)

        # æ˜¾ç¤ºå½“å‰è½®æ•°çš„ç»“æœ
        print(f"   è®­ç»ƒæŸå¤±ï¼š{train_loss:.4f}")
        print(f"   è®­ç»ƒå‡†ç¡®ç‡ï¼š{train_acc:.4f}")
        print(f"   æµ‹è¯•å‡†ç¡®ç‡ï¼š{test_acc:.4f}")

        # æ›´æ–°åŠ¨ç”»å™¨
        animator.add(epoch + 1, (train_loss, train_acc, test_acc))

    # éªŒè¯æœ€ç»ˆç»“æœ
    print(f"\nâœ… è®­ç»ƒå®Œæˆï¼æœ€ç»ˆç»“æœï¼š")
    print(f"   è®­ç»ƒæŸå¤±ï¼š{train_loss:.4f}")
    print(f"   è®­ç»ƒå‡†ç¡®ç‡ï¼š{train_acc:.4f}")
    print(f"   æµ‹è¯•å‡†ç¡®ç‡ï¼š{test_acc:.4f}")

    # æ£€æŸ¥è®­ç»ƒæ˜¯å¦æˆåŠŸ
    assert train_loss < 0.5, f"è®­ç»ƒæŸå¤±è¿‡é«˜: {train_loss}"
    assert train_acc <= 1 and train_acc > 0.7, f"è®­ç»ƒå‡†ç¡®ç‡å¼‚å¸¸: {train_acc}"
    assert test_acc <= 1 and test_acc > 0.7, f"æµ‹è¯•å‡†ç¡®ç‡å¼‚å¸¸: {test_acc}"
    print("ğŸ‰ æ‰€æœ‰æŒ‡æ ‡éƒ½åœ¨åˆç†èŒƒå›´å†…ï¼Œè®­ç»ƒæˆåŠŸï¼")

# ==================== ç¬¬åæ­¥ï¼šé¢„æµ‹å’Œå¯è§†åŒ–å‡½æ•° ====================

def predict_ch3(net: Union[torch.nn.Module, Any], test_iter: DataLoader, n: int = 6) -> None:
    """
    é¢„æµ‹å‡½æ•°ï¼šå±•ç¤ºæ¨¡å‹çš„é¢„æµ‹ç»“æœ
    å°±åƒè®©å­¦ç”Ÿå±•ç¤ºå­¦ä¹ æˆæœ

    å‚æ•°ï¼š
    net: è®­ç»ƒå¥½çš„ç½‘ç»œæ¨¡å‹
    test_iter: æµ‹è¯•æ•°æ®
    n: è¦æ˜¾ç¤ºçš„å›¾ç‰‡æ•°é‡
    """
    print(f"\nğŸ” å±•ç¤ºé¢„æµ‹ç»“æœï¼ˆæ˜¾ç¤º {n} å¼ å›¾ç‰‡ï¼‰...")

    # è·å–ä¸€æ‰¹æµ‹è¯•æ•°æ®
    for X, y in test_iter:
        break

    # è·å–çœŸå®æ ‡ç­¾å’Œé¢„æµ‹æ ‡ç­¾
    trues = d2l.get_fashion_mnist_labels(y)  # çœŸå®æ ‡ç­¾
    preds = d2l.get_fashion_mnist_labels(net(X).argmax(dim=1))  # é¢„æµ‹æ ‡ç­¾

    # åˆ›å»ºæ ‡é¢˜ï¼ˆæ˜¾ç¤ºçœŸå®å€¼å’Œé¢„æµ‹å€¼ï¼‰
    titles = [true + '\n' + pred for true, pred in zip(trues, preds)]

    # è®¡ç®—æ˜¾ç¤ºå¸ƒå±€
    rows = (n + 5) // 6  # è¡Œæ•°
    cols = min(n, 6)     # åˆ—æ•°ï¼ˆæœ€å¤š6åˆ—ï¼‰

    # æ˜¾ç¤ºå›¾ç‰‡å’Œé¢„æµ‹ç»“æœ
    d2l.show_images(X[0:n].reshape(n, 28, 28), rows, cols, titles=titles)

    print("âœ… é¢„æµ‹ç»“æœå±•ç¤ºå®Œæˆï¼")
    print("ğŸ’¡ æç¤ºï¼šæ¯å¼ å›¾ç‰‡ä¸Šæ–¹æ˜¾ç¤ºçœŸå®æ ‡ç­¾ï¼Œä¸‹æ–¹æ˜¾ç¤ºé¢„æµ‹æ ‡ç­¾")

# ==================== ç¬¬åä¸€æ­¥ï¼šä¸»ç¨‹åº ====================

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ“ Softmaxå›å½’ - ä»é›¶å¼€å§‹å®ç°")
    print("ğŸ“š è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„æœºå™¨å­¦ä¹ é¡¹ç›®")
    print("=" * 60)

    try:
        # è®¾ç½®è®­ç»ƒå‚æ•°
        num_epochs = 6  # è®­ç»ƒè½®æ•°
        print(f"\nâš™ï¸ è®­ç»ƒå‚æ•°ï¼š")
        print(f"   è®­ç»ƒè½®æ•°ï¼š{num_epochs}")
        print(f"   æ‰¹æ¬¡å¤§å°ï¼š{batch_size}")
        print(f"   å­¦ä¹ ç‡ï¼š{lr}")

        # å¼€å§‹è®­ç»ƒ
        print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)

        # å±•ç¤ºé¢„æµ‹ç»“æœ
        print(f"\nğŸ¨ å±•ç¤ºæ¨¡å‹é¢„æµ‹èƒ½åŠ›...")
        predict_ch3(net, test_iter, 18)  # æ˜¾ç¤º18å¼ å›¾ç‰‡çš„é¢„æµ‹ç»“æœ

        # è®­ç»ƒå®Œæˆ
        print(f"\nğŸ‰ é¡¹ç›®å®Œæˆï¼")
        print(f"ğŸ“Š è®­ç»ƒè¿‡ç¨‹å›¾å½¢å·²ä¿å­˜åˆ° ./plots/training_progress.png")

        # ä¿æŒå›¾å½¢æ˜¾ç¤ºï¼ˆåœ¨éJupyterç¯å¢ƒä¸­ï¼‰
        if not 'ipykernel' in sys.modules:
            plt.show(block=True)
            input("æŒ‰å›è½¦é”®å…³é—­å›¾å½¢çª—å£...")

    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        print("\nğŸ’¡ æç¤ºï¼šå¦‚æœé‡åˆ°é”™è¯¯ï¼Œè¯·æ£€æŸ¥ï¼š")
        print("   1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ï¼ˆéœ€è¦ä¸‹è½½æ•°æ®é›†ï¼‰")
        print("   2. æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´")
        print("   3. Pythonç¯å¢ƒæ˜¯å¦æ­£ç¡®é…ç½®")

print("\n" + "=" * 60)
print("ğŸ“– å­¦ä¹ æ€»ç»“ï¼š")
print("   1. æ•°æ®åŠ è½½ï¼šå‡†å¤‡å­¦ä¹ ææ–™")
print("   2. æ¨¡å‹æ„å»ºï¼šè®¾è®¡æ€è€ƒæ–¹å¼")
print("   3. æŸå¤±å‡½æ•°ï¼šå®šä¹‰é”™è¯¯æ ‡å‡†")
print("   4. ä¼˜åŒ–å™¨ï¼šæ”¹è¿›å­¦ä¹ æ–¹æ³•")
print("   5. è®­ç»ƒè¿‡ç¨‹ï¼šåå¤ç»ƒä¹ æ”¹è¿›")
print("   6. è¯„ä¼°ç»“æœï¼šæ£€æŸ¥å­¦ä¹ æ•ˆæœ")
print("=" * 60)
